{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114a5579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Header Tags\n",
      "0                       Main Page\n",
      "1            Welcome to Wikipedia\n",
      "2   From today's featured article\n",
      "3                Did you knowÂ ...\n",
      "4                     In the news\n",
      "5                     On this day\n",
      "6      From today's featured list\n",
      "7        Today's featured picture\n",
      "8        Other areas of Wikipedia\n",
      "9     Wikipedia's sister projects\n",
      "10            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "\n",
    "# Send a GET request to fetch the content\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "# Parse the HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "header_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "header_text = [tag.text.strip() for tag in header_tags]\n",
    "\n",
    "df = pd.DataFrame({'Header Tags': header_text})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160ba69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Team Matches Points Rating\n",
      "0    Australia\\nAUS      23  2,714    118\n",
      "1     Pakistan\\nPAK      20  2,316    116\n",
      "2        India\\nIND      36  4,081    113\n",
      "3   New Zealand\\nNZ      27  2,806    104\n",
      "4      England\\nENG      24  2,426    101\n",
      "5  South Africa\\nSA      19  1,910    101\n",
      "6   Bangladesh\\nBAN      28  2,661     95\n",
      "7  Afghanistan\\nAFG      16  1,404     88\n",
      "8     Sri Lanka\\nSL      32  2,794     87\n",
      "9   West Indies\\nWI      38  2,582     68\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the ICC Cricket rankings page\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "ranking_table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "teams = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "\n",
    "for row in ranking_table.find_all('tr')[1:11]:  \n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) >= 5:\n",
    "        team = columns[1].text.strip()\n",
    "        match = columns[2].text.strip()\n",
    "        point = columns[3].text.strip()\n",
    "        rating = columns[4].text.strip()\n",
    "        teams.append(team)\n",
    "        matches.append(match)\n",
    "        points.append(point)\n",
    "        ratings.append(rating)\n",
    "\n",
    "team_data = {\n",
    "    'Team': teams,\n",
    "    'Matches': matches,\n",
    "    'Points': points,\n",
    "    'Rating': ratings\n",
    "}\n",
    "df = pd.DataFrame(team_data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61609e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Player Team Rating\n",
      "0             Babar Azam  PAK    886\n",
      "1  Rassie van der Dussen   SA    777\n",
      "2           Fakhar Zaman  PAK    755\n",
      "3            Imam-ul-Haq  PAK    745\n",
      "4           Shubman Gill  IND    743\n",
      "5           Harry Tector  IRE    726\n",
      "6           David Warner  AUS    726\n",
      "7        Quinton de Kock   SA    718\n",
      "8            Virat Kohli  IND    705\n",
      "9            Steve Smith  AUS    702\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the ICC Cricket rankings page for ODI Batsmen\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "\n",
    "ranking_table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "players = []\n",
    "teams = []\n",
    "ratings = []\n",
    "\n",
    "for row in ranking_table.find_all('tr')[1:11]:\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) >= 4:\n",
    "        player = columns[1].text.strip()\n",
    "        team = columns[2].text.strip()\n",
    "        rating = columns[3].text.strip()\n",
    "        players.append(player)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "\n",
    "batting_data = {\n",
    "    'Player': players,\n",
    "    'Team': teams,\n",
    "    'Rating': ratings\n",
    "}\n",
    "df = pd.DataFrame(batting_data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4cfca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Player Team Rating\n",
      "0    Josh Hazlewood  AUS    705\n",
      "1    Mitchell Starc  AUS    686\n",
      "2       Rashid Khan  AFG    682\n",
      "3    Mohammed Siraj  IND    670\n",
      "4        Matt Henry   NZ    667\n",
      "5  Mujeeb Ur Rahman  AFG    661\n",
      "6       Trent Boult   NZ    660\n",
      "7        Adam Zampa  AUS    652\n",
      "8    Shaheen Afridi  PAK    630\n",
      "9     Kuldeep Yadav  IND    622\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the ICC Cricket rankings page for ODI Bowlers\n",
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "ranking_table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "\n",
    "players = []\n",
    "teams = []\n",
    "ratings = []\n",
    "\n",
    "for row in ranking_table.find_all('tr')[1:11]: \n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) >= 4:\n",
    "        player = columns[1].text.strip()\n",
    "        team = columns[2].text.strip()\n",
    "        rating = columns[3].text.strip()\n",
    "        players.append(player)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "\n",
    "bowling_data = {\n",
    "    'Player': players,\n",
    "    'Team': teams,\n",
    "    'Rating': ratings\n",
    "}\n",
    "df = pd.DataFrame(bowling_data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91363464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Team Matches Points Rating\n",
      "0    Australia\\nAUS      26  4,290    165\n",
      "1      England\\nENG      31  3,875    125\n",
      "2  South Africa\\nSA      26  3,098    119\n",
      "3        India\\nIND      30  3,039    101\n",
      "4   New Zealand\\nNZ      28  2,688     96\n",
      "5   West Indies\\nWI      29  2,743     95\n",
      "6   Bangladesh\\nBAN      17  1,284     76\n",
      "7     Sri Lanka\\nSL      12    820     68\n",
      "8     Thailand\\nTHA      13    883     68\n",
      "9     Pakistan\\nPAK      27  1,678     62\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the ICC Cricket rankings page for Women's ODI teams\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "ranking_table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "teams = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "\n",
    "for row in ranking_table.find_all('tr')[1:11]:\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) >= 5:\n",
    "        team = columns[1].text.strip()\n",
    "        match = columns[2].text.strip()\n",
    "        point = columns[3].text.strip()\n",
    "        rating = columns[4].text.strip()\n",
    "        teams.append(team)\n",
    "        matches.append(match)\n",
    "        points.append(point)\n",
    "        ratings.append(rating)\n",
    "\n",
    "team_data = {\n",
    "    'Team': teams,\n",
    "    'Matches': matches,\n",
    "    'Points': points,\n",
    "    'Rating': ratings\n",
    "}\n",
    "df = pd.DataFrame(team_data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13e7a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Player Team Rating\n",
      "0  Natalie Sciver-Brunt  ENG    803\n",
      "1   Chamari Athapaththu   SL    758\n",
      "2           Beth Mooney  AUS    751\n",
      "3       Laura Wolvaardt   SA    732\n",
      "4       Smriti Mandhana  IND    708\n",
      "5          Alyssa Healy  AUS    702\n",
      "6      Harmanpreet Kaur  IND    694\n",
      "7          Ellyse Perry  AUS    686\n",
      "8           Meg Lanning  AUS    682\n",
      "9       Stafanie Taylor   WI    618\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the ICC Cricket rankings page for Women's ODI Batting players\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "ranking_table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "players = []\n",
    "teams = []\n",
    "ratings = []\n",
    "\n",
    "for row in ranking_table.find_all('tr')[1:11]:\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) >= 4:\n",
    "        player = columns[1].text.strip()\n",
    "        team = columns[2].text.strip()\n",
    "        rating = columns[3].text.strip()\n",
    "        players.append(player)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "\n",
    "batting_data = {\n",
    "    'Player': players,\n",
    "    'Team': teams,\n",
    "    'Rating': ratings\n",
    "}\n",
    "df = pd.DataFrame(batting_data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c3748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Player Team Rating\n",
      "0  Natalie Sciver-Brunt  ENG    421\n",
      "1      Ashleigh Gardner  AUS    389\n",
      "2       Hayley Matthews   WI    382\n",
      "3        Marizanne Kapp   SA    349\n",
      "4          Ellyse Perry  AUS    329\n",
      "5           Amelia Kerr   NZ    328\n",
      "6         Deepti Sharma  IND    312\n",
      "7         Jess Jonassen  AUS    241\n",
      "8         Sophie Devine   NZ    233\n",
      "9              Nida Dar  PAK    232\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "ranking_table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "players = []\n",
    "teams = []\n",
    "ratings = []\n",
    "\n",
    "\n",
    "for row in ranking_table.find_all('tr')[1:11]:\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) >= 4:\n",
    "        player = columns[1].text.strip()\n",
    "        team = columns[2].text.strip()\n",
    "        rating = columns[3].text.strip()\n",
    "        players.append(player)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "\n",
    "all_rounder_data = {\n",
    "    'Player': players,\n",
    "    'Team': teams,\n",
    "    'Rating': ratings\n",
    "}\n",
    "df = pd.DataFrame(all_rounder_data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367ae420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Headline]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "headline_elements = soup.find_all('h3', {'class': 'Card-title'})\n",
    "\n",
    "headlines = [element.text.strip() for element in headline_elements]\n",
    "\n",
    "data = {'Headline': headlines}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696dd04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Time\n",
      "0        30 Min Ago\n",
      "1        34 Min Ago\n",
      "2        35 Min Ago\n",
      "3       2 Hours Ago\n",
      "4       2 Hours Ago\n",
      "5       2 Hours Ago\n",
      "6       2 Hours Ago\n",
      "7       2 Hours Ago\n",
      "8       2 Hours Ago\n",
      "9      21 Hours Ago\n",
      "10     22 Hours Ago\n",
      "11     23 Hours Ago\n",
      "12  August 19, 2023\n",
      "13  August 19, 2023\n",
      "14  August 19, 2023\n",
      "15  August 19, 2023\n",
      "16  August 19, 2023\n",
      "17  August 19, 2023\n",
      "18  August 19, 2023\n",
      "19  August 19, 2023\n",
      "20  August 19, 2023\n",
      "21  August 19, 2023\n",
      "22  August 19, 2023\n",
      "23  August 19, 2023\n",
      "24  August 19, 2023\n",
      "25  August 18, 2023\n",
      "26  August 18, 2023\n",
      "27  August 18, 2023\n",
      "28  August 18, 2023\n",
      "29  August 18, 2023\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "timestamp_elements = soup.find_all('time')\n",
    "\n",
    "timestamps = [element.text.strip() for element in timestamp_elements]\n",
    "\n",
    "data = {'Time': timestamps}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6ef5c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [News Link]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "\n",
    "link_elements = soup.find_all('a', {'class': 'Card-titleLink'})\n",
    "\n",
    "links = [element['href'] for element in link_elements]\n",
    "\n",
    "base_url = 'https://www.cnbc.com'\n",
    "full_links = [base_url + link for link in links]\n",
    "\n",
    "data = {'News Link': full_links}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1da3d2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Paper Title, Authors, Published Date, Paper URL]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the most downloaded articles page\n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "\n",
    "# Send a GET request to fetch the content\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "# Parse the HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Find all article elements\n",
    "article_elements = soup.find_all('li', {'class': 'pod-listing'})\n",
    "\n",
    "# Initialize lists to store article data\n",
    "titles = []\n",
    "authors = []\n",
    "published_dates = []\n",
    "paper_urls = []\n",
    "\n",
    "# Extract information from the article elements\n",
    "for article in article_elements:\n",
    "    title = article.find('h3').text.strip()\n",
    "    author = article.find('div', {'class': 'text-s'}).text.strip()\n",
    "    published_date = article.find('div', {'class': 'text-xs'}).text.strip()\n",
    "    paper_url = article.find('a')['href']\n",
    "    \n",
    "    titles.append(title)\n",
    "    authors.append(author)\n",
    "    published_dates.append(published_date)\n",
    "    paper_urls.append(paper_url)\n",
    "\n",
    "data = {\n",
    "    'Paper Title': titles,\n",
    "    'Authors': authors,\n",
    "    'Published Date': published_dates,\n",
    "    'Paper URL': paper_urls\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the dineout.co.in page\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants'\n",
    "\n",
    "response = requests.get(url)\n",
    "content = response.content\n",
    "\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "\n",
    "restaurant_elements = soup.find_all('div', {'class': 'restnt-info'})\n",
    "\n",
    "\n",
    "restaurant_names = []\n",
    "cuisines = []\n",
    "locations = []\n",
    "ratings = []\n",
    "image_urls = []\n",
    "\n",
    "\n",
    "for element in restaurant_elements:\n",
    "    restaurant_name = element.find('h3').text.strip()\n",
    "    cuisine = element.find('div', {'class': 'double-line'}).find('span').text.strip()\n",
    "    location = element.find('div', {'class': 'restnt-loc'}).text.strip()\n",
    "    rating = element.find('div', {'class': 'rating-popup'}).text.strip()\n",
    "    image_url = element.find('div', {'class': 'poster-thumb'}).find('img')['data-src']\n",
    "    \n",
    "    restaurant_names.append(restaurant_name)\n",
    "    cuisines.append(cuisine)\n",
    "    locations.append(location)\n",
    "    ratings.append(rating)\n",
    "    image_urls.append(image_url)\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Restaurant Name': restaurant_names,\n",
    "    'Cuisine': cuisines,\n",
    "    'Location': locations,\n",
    "    'Ratings': ratings,\n",
    "    'Image URL': image_urls\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
